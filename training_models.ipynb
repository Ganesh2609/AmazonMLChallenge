{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "from models import ResformerEncoder, ResformerDecoder\n",
    "from dataset import AmazonImageData\n",
    "from trainer import model_trainer\n",
    "import tokens\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1\n",
    "ENCODER_SAVE_PATH = 'models/first_encoder.pth'\n",
    "DECODER_SAVE_PATH = 'models/first_decoder.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens, output_tokens = tokens.get_tokens()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(400, 400)),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'amazon files/data/train.csv'\n",
    "img_root = 'dataset/train'\n",
    "data = AmazonImageData(root=root, img_root=img_root, input_tokens=input_tokens, output_tokens=output_tokens, max_seq_len=64, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset=data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "len(data), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating model instances \n",
    "\n",
    "encoder = ResformerEncoder().to(device)\n",
    "decoder = ResformerDecoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = Path(ENCODER_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    encoder.load_state_dict(torch.load(f=ENCODER_SAVE_PATH))\n",
    "    print(\"1) Exists\")\n",
    "else:\n",
    "    print(\"1) Creating\")\n",
    "    \n",
    "model_file = Path(DECODER_SAVE_PATH)\n",
    "if model_file.is_file():\n",
    "    decoder.load_state_dict(torch.load(f=DECODER_SAVE_PATH))\n",
    "    print(\"2) Exists\")\n",
    "else:\n",
    "    print(\"2) Creating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, optimizer and gradscaler \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=LEARNING_RATE)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer(encoder=encoder, decoder=decoder, dataloader=dataloader, loss_fn=loss_fn, optimizer=optimizer, scaler=scaler, epochs=NUM_EPOCHS, device=device, encoder_save_path=ENCODER_SAVE_PATH, decoder_save_path=DECODER_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
